{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of sysODE_keras_test.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPxFJrJhXOSRTLlDoBKIQyU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matinmoezzi/ebola-virus-ode-dnn/blob/main/system%20of%20ODE_keras_lbfgs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH8ndCajbQcN"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AI78gy9eszH"
      },
      "source": [
        "train_size = 10000\n",
        "test_size = 2000\n",
        "batch_size = 32\n",
        "epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrqymngPfBMq"
      },
      "source": [
        "x_min = -2\n",
        "x_max = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3aG8n1neMI6"
      },
      "source": [
        "x_train = tf.random.uniform(shape=[train_size, 1], minval=x_min, maxval=x_max)\n",
        "x_test = tf.linspace(x_min, x_max - 1, num=test_size)[:, tf.newaxis]\n",
        "x_test = tf.cast(x_test, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kxTntgziCLc"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4cHL6q4lHPz"
      },
      "source": [
        "def loss_fn(inputs, grad, logit, init_val):\n",
        "  ode_loss = grad + 2*inputs*logit \n",
        "  init_loss = init_val - 1\n",
        "  return tf.reduce_sum(tf.square(ode_loss)) + tf.reduce_sum(tf.square(init_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG7BU6jCYtd-"
      },
      "source": [
        "def loss_val_grad(model, inputs):\n",
        "\n",
        "  shapes = tf.shape_n(model.trainable_weights)\n",
        "  n_tensors = len(shapes)\n",
        "\n",
        "  # we'll use tf.dynamic_stitch and tf.dynamic_partition later, so we need to\n",
        "  # prepare required information first\n",
        "  count = 0\n",
        "  idx = [] # stitch indices\n",
        "  part = [] # partition indices\n",
        "\n",
        "  for i, shape in enumerate(shapes):\n",
        "    n = np.product(shape)\n",
        "    idx.append(tf.reshape(tf.range(count, count+n, dtype=tf.int32), shape))\n",
        "    part.extend([i]*n)\n",
        "    count += n\n",
        "\n",
        "  part = tf.constant(part)\n",
        "\n",
        "  def update_params(params):\n",
        "    params_var = tf.dynamic_partition(params, part, n_tensors)\n",
        "    for i, (shape, param) in enumerate(zip(shapes, params_var)):\n",
        "         model.trainable_variables[i].assign(tf.reshape(param, shape))\n",
        "\n",
        "  def func(params):\n",
        "    update_params(params)\n",
        "    with tf.GradientTape(persistent=True) as tp:\n",
        "      with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "        tape.watch(inputs)\n",
        "        logit = model(inputs)\n",
        "      df_dx = tape.gradient(logit, inputs)\n",
        "      loss_val = loss_fn(inputs, df_dx, logit, model(tf.constant([[0.0]])))\n",
        "    grads = tp.gradient(loss_val, model.trainable_weights)\n",
        "    grads = tf.dynamic_stitch(idx, grads)\n",
        "    return loss_val, grads\n",
        "\n",
        "  func.idx = idx\n",
        "  func.part = part\n",
        "  func.shapes = shapes\n",
        "  func.update_params = update_params\n",
        "\n",
        "  return func"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9FMkQl1c63s"
      },
      "source": [
        "nn = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "nn.build(input_shape=(None,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyr65W7yd_jJ"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"\\nStart of epoch {epoch}:\")\n",
        "  for step, x_batch_train in enumerate(test_dataset):\n",
        "    val_grad_func = loss_val_grad(nn, x_batch_train)\n",
        "    lbfgs_init_pos = tf.dynamic_stitch(val_grad_func.idx, nn.trainable_weights)\n",
        "    optim_results = tfp.optimizer.lbfgs_minimize(val_grad_func, initial_position=lbfgs_init_pos, max_iterations=100)\n",
        "    val_grad_func.update_params(optim_results.position)\n",
        "    \n",
        "    # Callback\n",
        "    if (optim_results.objective_value.numpy() < 1e-7):\n",
        "      break\n",
        "    \n",
        "    # if step % 100 == 0:\n",
        "    print(f\"\\tTraining loss at step {step}: {optim_results.objective_value.numpy()}\")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn_4s2XWgyqz"
      },
      "source": [
        "xs = np.linspace(-2,2,num=400)\n",
        "plt.plot(xs, np.exp(-xs**2), label='exact')\n",
        "plt.plot(xs, nn(tf.convert_to_tensor(xs)[:,tf.newaxis]), label='approx')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gluGWU3MMSP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}